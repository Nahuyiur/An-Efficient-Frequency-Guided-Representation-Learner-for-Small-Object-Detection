%%%%%%%% ICML 2026 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2026} with \usepackage[nohyperref]{icml2026} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2026}

% For preprint, use
% \usepackage[preprint]{icml2026}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2026}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}


% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2026}

\begin{document}

\twocolumn[
  \icmltitle{Submission and Formatting Instructions for \\
    International Conference on Machine Learning (ICML 2026)}

  % It is OKAY to include author information, even for blind submissions: the
  % style file will automatically remove it for you unless you've provided
  % the [accepted] option to the icml2026 package.

  % List of affiliations: The first argument should be a (short) identifier you
  % will use later to specify author affiliations Academic affiliations
  % should list Department, University, City, Region, Country Industry
  % affiliations should list Company, City, Region, Country

  % You can specify symbols, otherwise they are numbered in order. Ideally, you
  % should not use this facility. Affiliations will be numbered in order of
  % appearance and this is the preferred way.
  \icmlsetsymbol{equal}{*}

  \begin{icmlauthorlist}
    \icmlauthor{Firstname1 Lastname1}{equal,yyy}
    \icmlauthor{Firstname2 Lastname2}{equal,yyy,comp}
    \icmlauthor{Firstname3 Lastname3}{comp}
    \icmlauthor{Firstname4 Lastname4}{sch}
    \icmlauthor{Firstname5 Lastname5}{yyy}
    \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
    \icmlauthor{Firstname7 Lastname7}{comp}
    %\icmlauthor{}{sch}
    \icmlauthor{Firstname8 Lastname8}{sch}
    \icmlauthor{Firstname8 Lastname8}{yyy,comp}
    %\icmlauthor{}{sch}
    %\icmlauthor{}{sch}
  \end{icmlauthorlist}

  \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
  \icmlaffiliation{comp}{Company Name, Location, Country}
  \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

  \icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
  \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

  % You may provide any keywords that you find helpful for describing your
  % paper; these are used to populate the "keywords" metadata in the PDF but
  % will not be shown in the document
  \icmlkeywords{Machine Learning, ICML}

  \vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column listing the
% affiliations and the copyright notice. The command takes one argument, which
% is text to display at the start of the footnote. The \icmlEqualContribution
% command is standard text for equal contribution. Remove it (just {}) if you
% do not need this facility.

% Use ONE of the following lines. DO NOT remove the command.
% If you have no special notice, KEEP empty braces:
\printAffiliationsAndNotice{}  % no special notice (required even if empty)
% Or, if applicable, use the standard equal contribution text:
% \printAffiliationsAndNotice{\icmlEqualContribution}

\begin{abstract}
  This document provides a basic paper template and submission guidelines.
  Abstracts must be a single paragraph, ideally between 4--6 sentences long.
  Gross violations will trigger corrections at the camera-ready phase.
\end{abstract}

\section{Introduction}

\section{Related Work}

This section reviews related work from three perspectives: efficient network architecture design, small object detection, and frequency domain analysis in object detection.

\subsection{Efficient Network Architecture Design}

Efficient network architectures are crucial for real-time object detection. The YOLO series has been a cornerstone, with recent iterations like YOLOv10 \cite{yolov10} and YOLOv11 \cite{yolov11} achieving improvements in accuracy and speed. FBRT-YOLO \cite{fbrt-yolo} further enhances YOLO for small object detection through feature complementary mapping modules and multi-kernel perception units.

Beyond YOLO, DETR (Detection Transformer) \cite{detr} eliminated anchor boxes and introduced end-to-end detection, though its quadratic complexity limits efficiency. RT-DETR \cite{rt-detr} and DINO \cite{dino} address this through efficient attention mechanisms. ELAN \cite{elan} and LSNet \cite{lsnet} demonstrate effective layer aggregation strategies, with LSNet employing large kernels for global perception and small kernels for local aggregation. MobileU-ViT \cite{mobileuvit} combines CNNs and Transformers in a lightweight framework using large-kernel depthwise separable convolutions.

\subsection{Small Object Detection}

Small object detection faces challenges due to limited spatial information and weak feature responses. Traditional frameworks like Faster R-CNN \cite{fasterrcnn} and SSD \cite{ssd} lose critical information during downsampling. HS-FPN \cite{hs-fpn} addresses this by leveraging discrete cosine transform (DCT) to extract high-frequency components through a High-frequency Perception (HFP) module and capturing pixel-level spatial dependencies via a Spatial Dependency Perception (SDP) module.

Multi-scale feature fusion approaches build upon Feature Pyramid Networks (FPN) \cite{fpn}, with recent enhancements incorporating attention mechanisms and specialized modules for small object detection \cite{hs-fpn}. Context information modeling through large receptive fields also proves effective. LSNet \cite{lsnet} combines large and small kernels for global and local context, while FBRT-YOLO \cite{fbrt-yolo} employs multi-kernel perception units to capture cross-scale relationships efficiently.

\subsection{Frequency Domain Analysis in Object Detection}

Frequency domain analysis offers complementary perspectives for feature extraction. Global Filter Networks (GFNet) \cite{gfnet} replace self-attention layers with global filter layers using 2D FFT/IFFT, achieving linear complexity while maintaining global receptive fields. Frequency Dynamic Convolution (FDConv) \cite{fdconv} constructs frequency-disentangled convolution kernels by dividing the spectrum into low, medium, and high-frequency bands, with Kernel Spectrum Modulation (KSM) and Frequency Band Modulation (FBM) for adaptive weighting.

Wavelet-based methods also demonstrate effectiveness. Haar wavelet downsampling \cite{haar} preserves edge and texture information crucial for small object detection. Wavelet Convolutions (WTConv) \cite{wtconv} expand receptive fields with logarithmic complexity growth. Adaptive Complex Wavelet Informed Transformer Operators \cite{wavelet-transformer} integrate complex wavelet transforms into Transformers for multi-resolution analysis, showing that frequency domain techniques can be seamlessly integrated into modern architectures.


\bibliography{example_paper}
\bibliographystyle{icml2026}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{You \emph{can} have an appendix here.}

You can have as much text here as you want. The main body must be at most $8$
pages long. For the final version, one more page can be added. If you want, you
can use an appendix like this one.

The $\mathtt{\backslash onecolumn}$ command above can be kept in place if you
prefer a one-column appendix, or can be removed if you prefer a two-column
appendix.  Apart from this possible change, the style (font size, spacing,
margins, page numbering, etc.) should be kept the same as the main body.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
